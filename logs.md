Train logs

- LoRA (8/32): 0.30 M trainable parameters, 124.74 M total parameters. [0.24%] 2672 MB GPU
- **LoRA (32/32)**: 1.19 M trainable parameters, 125.63 M total parameters. [0.95%] 2688 MB GPU
- LoRA (128/128): 4.73 M trainable parameters, 129.17 M total parameters. [3.66%] 2712 MB GPU

- SoftPrompt (20): 0.02 M trainable parameters, 124.46 M total parameters. [0.01%] 3018 MB GPU
- SoftPrompt (100): 0.02 M trainable parameters, 124.46 M total parameters. [0.01%] 8720 MB GPU

- Train from Scratch: 123.82 M trainable parameters, 123.82 M total parameters. [100.00%] 3198 MB GPU